{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we will import the Groove Midi Dataset and process it, and save it for easily being used in our pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# For some reason, tfds import gives an error on the first attempt but works second time around\n",
    "try:                              \n",
    "    import tensorflow_datasets as tfds\n",
    "except:\n",
    "    import tensorflow_datasets as tfds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for processing/loading/storing the dataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import ipyparams\n",
    "from shutil import copy2\n",
    "\n",
    "# Import libraries for creating/naming folders/files\n",
    "import os, sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder Organization\n",
    "\n",
    "----\n",
    "    |\n",
    "    |--> HVO_Sequence\n",
    "    |\n",
    "    |\n",
    "    |--> GrooveMIDI2HVO_PreProcessing\n",
    "    |                                \\----> pre_processing_tutorial\n",
    "    |                                                             \\---> GrooveMIDI2HVO-Tutorial.ipynb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# Import the HVO_Sequence implementation\n",
    "sys.path.insert(0, \"../hvo_sequence\") # --> unnecessary in future implementations (when package installed via pip)\n",
    "!ls\n",
    "from hvo_sequence.io_helpers import note_sequence_to_hvo_sequence\n",
    "from hvo_sequence.drum_mappings import ROLAND_REDUCED_MAPPING\n",
    "\n",
    "# Import magenta's note_seq \n",
    "import note_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfds works in both Eager and Graph modes\n",
    "#tf.enable_eager_execution() #not needed in TF V2, as it is already the default\n",
    "#import magenta.music as mm \n",
    "# from magenta.models.music_vae import data   <---- DELETE\n",
    "#import magenta\n",
    "\n",
    "#print (magenta.__version__)\n",
    "#from visual_midi import Plotter\n",
    "#from pretty_midi import PrettyMIDI\n",
    "#from IPython.core.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have the dataset already available in tensorflow_datasets, so let's load it first\n",
    "\n",
    "\n",
    "#####  NOTE:\n",
    " you can convert midi to note_sequence, two ways:\n",
    " 1. USE magenta.music.midi_to_note_sequence, BUT THIS will GIVE YOU A PICKLING ERROR\n",
    " 2. install note_seq (pip install note_seq) then use note_seq.midi_to_note_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Start With the 2bar-midionly dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_unprocessed,dataset_train_info = tfds.load(\n",
    "    name=\"groove/2bar-midionly\",\n",
    "    split=tfds.Split.TRAIN,\n",
    "    try_gcs=True,\n",
    "    with_info=True)\n",
    "\n",
    "dataset_test_unprocessed = tfds.load(\n",
    "    name=\"groove/2bar-midionly\",\n",
    "    split=tfds.Split.TEST,\n",
    "    try_gcs=True)\n",
    "\n",
    "dataset_validation_unprocessed = tfds.load(\n",
    "    name=\"groove/2bar-midionly\",\n",
    "    split=tfds.Split.VALIDATION,\n",
    "    try_gcs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: TF DATASETS ARE PYTHON ITERABLES\n",
    "you can convert the dataset into a list or numpy array:\n",
    "\n",
    "   * List(dataset)\n",
    "   * tfds.as_numpy(dataset)\n",
    "    \n",
    "Lets see how many samples we've got in the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # In all three sets, separate entries into individual examples \n",
    "dataset_train = dataset_train_unprocessed.batch(1)\n",
    "dataset_test  = dataset_test_unprocessed.batch(1)\n",
    "dataset_validation = dataset_validation_unprocessed.batch(1)\n",
    "\n",
    "print(\"\\n Number of Examples in Train Set: {}, Test Set: {}, Validation Set: {}\".format(\n",
    "    len(list(dataset_train)), \n",
    "    len(list(dataset_test)), \n",
    "    len(list(dataset_validation)))\n",
    "     ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download groovemidi set (midi files and metadata of performances, not chopped files!) \n",
    "!mkdir resources\n",
    "!mkdir resources/source_dataset\n",
    "!wget -N -P resources/source_dataset https://storage.googleapis.com/magentadata/datasets/groove/groove-v1.0.0-midionly.zip\n",
    "!unzip -n resources/source_dataset/groove-v1.0.0-midionly.zip -d resources/source_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will start pre-process the downloaded 2-bar groove midi datasets.\n",
    "The metadata for the dataset is not available via the tfds.load() method. As a result, I have manually downloaded the groove-v1.0.0-midionly.zip dataset from here:\n",
    "        \n",
    "        https://magenta.tensorflow.org/datasets/groove\n",
    "        \n",
    "In this folder (currently in resources/source_dataset), there is a csv file containing the metadata for each of the examples. I will match each of the 2-bar examples (downloaded from tfds.load()) with the csv file available in the manually downloaded groove-v1.0.0-midionly.zip\n",
    "\n",
    "\n",
    "To keep track of the metadata, a panda's dataframe with the following fields is used\n",
    "\n",
    "* Keys from Groove MIDI Dataset:\n",
    "    * bpm\n",
    "    * drummer\n",
    "    * id \n",
    "    * midi\n",
    "    * style\n",
    "    * time_signature\n",
    "    * type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('resources/source_dataset/groove/info.csv', delimiter = ',')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick guide to using the panda dataframe\n",
    "(dataframe[dataframe.id == \"drummer1/eval_session/10\"]).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference between tfds.load(name=\"groove/2bar-midionly\") and groove-v1.0.0-midionly.zip\n",
    "\n",
    "In groove-v1.0.0-midionly.zip, we have access to full performances, while using tfds.load(name=\"groove/2bar-midionly\"), we can readily access the performance chopped into 2 bar segments. \n",
    "\n",
    "However, in the pre-chopped set, the meta data is missing. \n",
    "\n",
    "Hence, we need to find the relevant metadata in the info.csv file available groove-v1.0.0-midionly.zip. \n",
    "\n",
    "To do so, we match the beginning of the id in the chopped segments with the id in info.csv\n",
    "\n",
    "\n",
    "# Preprocessing Steps\n",
    "\n",
    "\n",
    "To preprocess the set, we will go through each of the examples in train/test/eval sets and do the following:\n",
    "\n",
    "    1. get the midi file from the \"midi\" field available from tfds.load()\n",
    "    2. convert midi to note_sequence \n",
    "    2. convert the note_sequence to HVO_Sequence\n",
    "    3. get the id from the \"id\" field available from tfds.load()\n",
    "    4. Match the beginning of the \"id\" field with the ids in the pandas dataframe (loaded from groove-v1.0.0-midionly.zip)\n",
    "    5. Store all processed/retrieved fields in a dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_append(dictionary, key, vals):\n",
    "    # Appends a value or a list of values to a key in a dictionary\n",
    "    \n",
    "    # if the values for a key are not a list, they are converted to a list and then extended with vals\n",
    "    dictionary[key]=list(dictionary[key]) if not isinstance(dictionary[key], list) else dictionary[key]\n",
    "    \n",
    "    # if vals is a single value (not a list), it's converted to a list so as to be iterable\n",
    "    vals = [vals] if not isinstance(vals, list) else vals\n",
    "        \n",
    "    # append new values \n",
    "    for val in vals:\n",
    "        dictionary[key].append(val)\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "def convert_groove_midi_dataset(dataset, beat_division_factors=[4], csv_dataframe_info=None):\n",
    "    \n",
    "    dataset_dict_processed = dict()\n",
    "    dataset_dict_processed.update({\n",
    "        \"drummer\":[],\n",
    "        \"session\":[],\n",
    "        \"loop_id\":[],  # the id of the recording from which the loop is extracted\n",
    "        \"master_id\":[], # the id of the recording from which the loop is extracted\n",
    "        \"style_primary\":[],\n",
    "        \"style_secondary\":[],\n",
    "        \"bpm\":[],\n",
    "        \"beat_type\":[],\n",
    "        \"time_signature\":[],\n",
    "        \"full_midi_filename\":[],\n",
    "        \"full_audio_filename\":[],\n",
    "        \"midi\":[],\n",
    "        \"note_sequence\":[],\n",
    "        \"hvo_sequence\":[],\n",
    "    })\n",
    "    \n",
    "    for features in dataset:\n",
    "        \n",
    "        # Features to be extracted from the dataset\n",
    "        \n",
    "        note_sequence = note_seq.midi_to_note_sequence(tfds.as_numpy(features[\"midi\"][0]))\n",
    "        \n",
    "        \n",
    "        if note_sequence.notes: # ignore if no notes in note_sequence (i.e. empty 2 bar sequence)\n",
    "                        \n",
    "            _hvo_seq = note_sequence_to_hvo_sequence(\n",
    "                ns = note_sequence, \n",
    "                drum_mapping = ROLAND_REDUCED_MAPPING,\n",
    "                beat_division_factors = beat_division_factors\n",
    "            )\n",
    "            \n",
    "            \n",
    "            if (not csv_dataframe_info.empty) and len(_hvo_seq.time_signatures)==1 and len(_hvo_seq.tempos)==1 :\n",
    "\n",
    "                # Master ID for the Loop\n",
    "                main_id = features[\"id\"].numpy()[0].decode(\"utf-8\").split(\":\")[0]\n",
    "\n",
    "                # Get the relevant series from the dataframe\n",
    "                df = csv_dataframe_info[csv_dataframe_info.id == main_id]\n",
    "                \n",
    "                # Update the dictionary associated with the metadata\n",
    "                dict_append(dataset_dict_processed, \"drummer\", df[\"drummer\"].to_numpy()[0])\n",
    "                _hvo_seq.metadata.drummer = df[\"drummer\"].to_numpy()[0]\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"session\", df[\"session\"].to_numpy()[0].split(\"/\")[-1])\n",
    "                _hvo_seq.metadata.session = df[\"session\"].to_numpy()[0]\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"loop_id\", features[\"id\"].numpy()[0].decode(\"utf-8\"))\n",
    "                _hvo_seq.metadata.loop_id = features[\"id\"].numpy()[0].decode(\"utf-8\")\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"master_id\", main_id)\n",
    "                _hvo_seq.metadata.master_id = main_id\n",
    "\n",
    "                style_full = df[\"style\"].to_numpy()[0]\n",
    "                style_primary = style_full.split(\"/\")[0]\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"style_primary\", style_primary)\n",
    "                _hvo_seq.metadata.style_primary = style_primary\n",
    "\n",
    "                \n",
    "                if \"/\" in style_full:\n",
    "                    style_secondary = style_full.split(\"/\")[1]\n",
    "                    dict_append(dataset_dict_processed, \"style_secondary\", style_secondary)\n",
    "                    _hvo_seq.metadata.style_secondary = style_secondary\n",
    "                else:\n",
    "                    dict_append(dataset_dict_processed, \"style_secondary\", [\"None\"])\n",
    "                    _hvo_seq.metadata.style_secondary = \"None\"\n",
    "\n",
    "                dict_append(dataset_dict_processed, \"bpm\", df[\"bpm\"].to_numpy()[0])\n",
    "\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"beat_type\", df[\"beat_type\"].to_numpy()[0])\n",
    "                _hvo_seq.metadata.beat_type = df[\"beat_type\"].to_numpy()[0]\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"time_signature\", df[\"time_signature\"].to_numpy()[0])\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"full_midi_filename\", df[\"midi_filename\"].to_numpy()[0])\n",
    "                _hvo_seq.metadata.full_midi_filename = df[\"midi_filename\"].to_numpy()[0]\n",
    "\n",
    "                dict_append(dataset_dict_processed, \"full_audio_filename\", df[\"audio_filename\"].to_numpy()[0])\n",
    "                _hvo_seq.metadata.full_audio_filename = df[\"audio_filename\"].to_numpy()[0]\n",
    "\n",
    "                dict_append(dataset_dict_processed, \"midi\", features[\"midi\"].numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"note_sequence\", [note_sequence])\n",
    "                        \n",
    "                dict_append(dataset_dict_processed, \"hvo_sequence\", _hvo_seq)\n",
    "\n",
    "        else:\n",
    "            pass \n",
    "            \n",
    "    return dataset_dict_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Process Training Set\n",
    "dataset_train = dataset_train_unprocessed.batch(1)\n",
    "dataset_train_processed = convert_groove_midi_dataset(\n",
    "    dataset = dataset_train, \n",
    "    beat_division_factors=[4], \n",
    "    csv_dataframe_info=dataframe\n",
    ")\n",
    "\n",
    "# Process Test Set\n",
    "dataset_test = dataset_test_unprocessed.batch(1)\n",
    "dataset_test_processed = convert_groove_midi_dataset(\n",
    "    dataset = dataset_test, \n",
    "    beat_division_factors=[4], \n",
    "    csv_dataframe_info=dataframe)\n",
    "\n",
    "# Process Validation Set\n",
    "dataset_validation = dataset_validation_unprocessed.batch(1)\n",
    "dataset_validation_processed = convert_groove_midi_dataset(\n",
    "    dataset = dataset_validation, \n",
    "    beat_division_factors=[4], \n",
    "    csv_dataframe_info=dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order the pre-processed set\n",
    "The batching process shuffles the dataset. However, we prefer to store the dataset in sequential order. Hence, we need to manually order the dataset. In this tutorial, I order the sequences by loop_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dictionary_by_key (dictionary_to_sort, key_used_to_sort):\n",
    "    # sorts a dictionary according to the list within a given key\n",
    "    sorted_ids=np.argsort(dictionary_to_sort[key_used_to_sort])\n",
    "    for key in dictionary_to_sort.keys():\n",
    "        dictionary_to_sort[key]=[dictionary_to_sort[key][i] for i in sorted_ids]\n",
    "    return dictionary_to_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the sets using ids\n",
    "dataset_train_processed = sort_dictionary_by_key(dataset_train_processed, \"loop_id\")\n",
    "dataset_test_processed = sort_dictionary_by_key(dataset_test_processed, \"loop_id\")\n",
    "dataset_validation_processed = sort_dictionary_by_key(dataset_validation_processed, \"loop_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "--------------------------------------\n",
    "\n",
    "# Storing Pre-Processed Sets\n",
    "\n",
    "The folder structure is as follows:\n",
    "\n",
    "./Preprocess_GMD2HVO_Sequence.ipynb\n",
    "\n",
    "./processed_dataset\n",
    "\n",
    "      |\n",
    "      |--> /Processed_On_%d_%m_%Y_at_%H_%M_hrs\n",
    "            |\n",
    "            |--> /GrooveMIDI_processed_{train, test, or validation}\n",
    "                    |\n",
    "                    |--> hvo_sequence.obj\n",
    "                    |\n",
    "                    |--> note_sequence.obj\n",
    "                    |\n",
    "                    |--> midi.obj\n",
    "                    |\n",
    "                    |--> midi.obj\n",
    "                    |\n",
    "                    |--> metadata.csv\n",
    "                    \n",
    "                    \n",
    "The midi files, hvo_sequences and note_sequences along with corresponding metadata are all saved in separate files. The order of entries in all these files match one another (increasing in alpha-numeric order of \"loopid\"s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMP INTO A PICKLE FILE\n",
    "def store_dataset_as_pickle(dataset_list, \n",
    "                            filename_list, \n",
    "                            root_dir = \"processed_dataset\",\n",
    "                            append_datetime=True, \n",
    "                            features_with_separate_picklefile = [\"hvo\", \"midi\", \"note_seq\"]\n",
    "                           ):\n",
    "\n",
    "    #filename = filename.split(\".obj\")[0]\n",
    "    path = root_dir\n",
    "    \n",
    "    if append_datetime:\n",
    "        now = datetime.now()\n",
    "        dt_string = now.strftime(\"%d_%m_%Y_at_%H_%M_hrs\")\n",
    "    else:\n",
    "        dt_string =\"\"\n",
    "        \n",
    "    path = os.path.join(path, \"Processed_On_\"+dt_string)\n",
    "    \n",
    "    if not os.path.exists (path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    currentNotebook = ipyparams.notebook_name\n",
    "    print(\"Copying Source Code from %s to %s\" % (os.path.join(os.getcwd(), currentNotebook), path))\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    # copy2(os.path.join(os.getcwd(), currentNotebook), path) \n",
    "    \n",
    "    for i, dataset in enumerate(dataset_list):\n",
    "\n",
    "        subdirectory = os.path.join(path, filename_list[i])\n",
    "        if not os.path.exists (subdirectory):\n",
    "            os.makedirs(subdirectory)\n",
    "            \n",
    "        print(\"-\"*100)\n",
    "        print(\"-\"*100)\n",
    "        print(\"Processing %s folder\" % subdirectory)\n",
    "        print(\"-\"*100)\n",
    "        print(\"-\"*100)\n",
    "        \n",
    "        # Create Metadata File\n",
    "        csv_dataframe = pd.DataFrame()\n",
    "        \n",
    "        for k in dataset.keys():\n",
    "            if k not in features_with_separate_picklefile:\n",
    "                csv_dataframe[k] = dataset[k]\n",
    "        \n",
    "        csv_dataframe.to_csv(os.path.join(subdirectory, \"metadata.csv\"))\n",
    "        \n",
    "        print(\"Metadata created!\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        for feature in features_with_separate_picklefile:\n",
    "            if feature in dataset.keys():\n",
    "                dataset_filehandler = open(os.path.join(subdirectory, \"%s_data.obj\"%feature),\"wb\")\n",
    "                print(feature)\n",
    "                print(dataset_filehandler)\n",
    "                pickle.dump(dataset[feature],  dataset_filehandler)\n",
    "                dataset_filehandler.close()\n",
    "                print(\"feature %s pickled at %s\" % (feature, os.path.join(subdirectory, \"%s.obj\"%filename_list[i].split(\".\")[0])))\n",
    "                print(\"-\"*100)\n",
    "\n",
    "            else:\n",
    "                 raise Warning(\"Feature is not available: \", feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = [dataset_train_processed,\n",
    "               dataset_test_processed,\n",
    "               dataset_validation_processed]\n",
    "\n",
    "filename_list = [\"GrooveMIDI_processed_train\",\n",
    "                \"GrooveMIDI_processed_test\",\n",
    "                \"GrooveMIDI_processed_validation\"]\n",
    "\n",
    "store_dataset_as_pickle(dataset_list, \n",
    "                        filename_list,\n",
    "                        root_dir=\"../processed_dataset\",\n",
    "                        append_datetime=True,\n",
    "                        features_with_separate_picklefile = [\"hvo_sequence\", \"midi\", \"note_sequence\"]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_list = [dataset_train_processed,\n",
    "               dataset_test_processed,\n",
    "               dataset_validation_processed]\n",
    "\n",
    "filename_list = [\"GrooveMIDI_processed_train\",\n",
    "                \"GrooveMIDI_processed_test\",\n",
    "                \"GrooveMIDI_processed_validation\"]\n",
    "\n",
    "store_dataset_as_pickle(dataset_list, \n",
    "                        filename_list,\n",
    "                        root_dir=\"processed_dataset\",\n",
    "                        append_datetime=True,\n",
    "                        features_with_separate_picklefile = [\"hvo_sequence\", \"midi\", \"note_sequence\"]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "----------\n",
    "\n",
    "### Using Pre-Processed Sets After Storing\n",
    "\n",
    "Now, we can import the pre-processed sets easily into our scripts without going through this procedure. \n",
    "\n",
    "To do so, load the pickle files and the metadata from corresponding subfolders!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"processed_dataset/Processed_On_16_05_2021_at_11_06_hrs\"\n",
    "print(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"hvo_data.obj\"))\n",
    "train_file = open(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"hvo_sequence_data.obj\"),'rb')\n",
    "train_set = pickle.load(train_file)\n",
    "metadata = pd.read_csv(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"metadata.csv\"))\n",
    "\n",
    "features_in_metadata = list(metadata.columns)\n",
    "\n",
    "dataset_size = len(train_set)\n",
    "\n",
    "print(\"Dataset Size: %d \\n Features: \" % dataset_size, features_in_metadata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvo_seq = train_set[102]\n",
    "hvo_seq.time_signatures\n",
    "hvo_seq.hvo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at a random entry!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix =  int(np.random.random_sample()*dataset_size)\n",
    "print(\"Sample Number: %d, Primary Style: %s, Secondary Style: %s\" % (ix, \n",
    "                                                                     metadata[\"style_secondary\"][ix], \n",
    "                                                                     metadata[\"style_primary\"][ix])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = train_set[ix].to_html_plot(filename=\"pre_processing_tutorial/misc/temp.html\")\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from copy import deepcopy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {\n",
    "    \"drummer\": None,               # [\"drummer1\", ..., and/or \"session9\"]\n",
    "    \"session\": None,               # [\"session1\", \"session2\", and/or \"session3\"]\n",
    "    \"loop_id\": None,\n",
    "    \"master_id\": None,\n",
    "    \"style_primary\": None,        # [funk, latin, jazz, rock, gospel, punk, hiphop, pop, soul, neworleans, afrobeat]\n",
    "    #\"style_secondary\" None,       # [fast, brazilian_baiao, funk, halftime, purdieshuffle, None, samba, chacarera, bomba, brazilian, brazilian_sambareggae, brazilian_samba, venezuelan_joropo, brazilian_frevo, fusion, motownsoft]\n",
    "    \"bpm\": None,                  # [(range_0_lower_bound, range_0_upper_bound), ..., (range_n_lower_bound, range_n_upper_bound)]\n",
    "    \"beat_type\": [\"beat\"],        # [\"beat\" or \"fill\"]\n",
    "    \"time_signature\": [\"4-4\"],    # [\"4-4\", \"3-4\", \"6-8\"]\n",
    "    \"full_midi_filename\": None,   # list_of full_midi_filenames\n",
    "    \"full_audio_filename\": None   # list_of full_audio_filename\n",
    "}\n",
    "\n",
    "def check_if_passes_filters(df_row, filters):\n",
    "    meets_filter = []\n",
    "    for filter_key, filter_values in zip(filters.keys(), filters.values()):\n",
    "        if filters[filter_key] is not None:\n",
    "            if df_row.at[filter_key] in filter_values:\n",
    "                meets_filter.append(True)\n",
    "            else:\n",
    "                meets_filter.append(False)\n",
    "    return all(meets_filter)\n",
    "    \n",
    "\n",
    "class GrooveMidiDataset(Dataset):\n",
    "    def __init__(self, source_path = \"processed_dataset/Processed_On_05_05_2021_at_01_09_hrs\", \n",
    "                 subset = \"GrooveMIDI_processed_train\",\n",
    "                 metadata_csv_filename = \"metadata.csv\", \n",
    "                 hvo_pickle_filename = \"hvo_sequence_data.obj\", \n",
    "                 filters = filters):\n",
    "        \n",
    "        train_file = open(os.path.join(source_path, subset, hvo_pickle_filename),'rb')\n",
    "        train_set = pickle.load(train_file)\n",
    "        metadata = pd.read_csv(os.path.join(source_path, subset, metadata_csv_filename))\n",
    "\n",
    "        features_in_metadata = list(metadata.columns)\n",
    "        \n",
    "        self.hvo_sequences = []\n",
    "        for ix, hvo_seq in enumerate(train_set):\n",
    "            if check_if_passes_filters(metadata.loc[ix], filters):\n",
    "                # add metadata to hvo_seq scores\n",
    "                hvo_seq.drummer = metadata.loc[ix].at[\"drummer\"]\n",
    "                hvo_seq.session = metadata.loc[ix].at[\"session\"]\n",
    "                hvo_seq.master_id = metadata.loc[ix].at[\"master_id\"]\n",
    "                hvo_seq.style_primary = metadata.loc[ix].at[\"style_primary\"]\n",
    "                hvo_seq.style_secondary = metadata.loc[ix].at[\"style_secondary\"]\n",
    "                hvo_seq.beat_type = metadata.loc[ix].at[\"beat_type\"]\n",
    "                self.hvo_sequences.append(hvo_seq)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.hvo_sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.hvo_sequences.hvo, idx\n",
    "        \n",
    "        \n",
    "filters_rock = deepcopy(filters)\n",
    "filters_rock[\"style_primary\"]=[\"rock\"]\n",
    "filters_funk = deepcopy(filters)\n",
    "filters_funk[\"style_primary\"]=[\"funk\"]\n",
    "\n",
    "train_set_rock = GrooveMidiDataset(filters = filters_rock)\n",
    "train_set_funk = GrooveMidiDataset(filters = filters_funk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set_rock.hvo_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set_funk.hvo_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_rock.hvo_sequences[0].session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_a[\"style_primary\"]=[\"rock\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_magenta_1_7_tf",
   "language": "python",
   "name": "torch_magenta_1_7_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
