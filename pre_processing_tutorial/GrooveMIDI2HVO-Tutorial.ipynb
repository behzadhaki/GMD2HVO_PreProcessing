{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we will import the Groove Midi Dataset and process it, and save it for easily being used in our pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "console.log('Starting front end url_querystring_target comm target');\n",
       "const comm = Jupyter.notebook.kernel.comm_manager.new_comm('url_querystring_target', {'init': 1});\n",
       "comm.send({'ipyparams_browser_url': window.location.href});\n",
       "console.log('Sent window.location.href on url_querystring_target comm target');\n",
       "\n",
       "comm.on_msg(function(msg) {\n",
       "    console.log(msg.content.data);\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# For some reason, tfds import gives an error on the first attempt but works second time around\n",
    "try:                              \n",
    "    import tensorflow_datasets as tfds\n",
    "except:\n",
    "    import tensorflow_datasets as tfds\n",
    "    \n",
    "# Import necessary libraries for processing/loading/storing the dataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import ipyparams\n",
    "from shutil import copy2\n",
    "\n",
    "# Import libraries for creating/naming folders/files\n",
    "import os, sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Import the HVO_Sequence implementation\n",
    "sys.path.append(\"../\") # --> unnecessary in future implementations (when package installed via pip)\n",
    "from hvo_sequence.io_helpers import note_sequence_to_hvo_sequence\n",
    "from hvo_sequence.drum_mappings import ROLAND_REDUCED_MAPPING\n",
    "\n",
    "# Import magenta's note_seq \n",
    "import note_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# tfds works in both Eager and Graph modes\n",
    "#tf.enable_eager_execution() #not needed in TF V2, as it is already the default\n",
    "#import magenta.music as mm \n",
    "# from magenta.models.music_vae import data   <---- DELETE\n",
    "#import magenta\n",
    "\n",
    "#print (magenta.__version__)\n",
    "#from visual_midi import Plotter\n",
    "#from pretty_midi import PrettyMIDI\n",
    "#from IPython.core.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have the dataset already available in tensorflow_datasets, so let's load it first\n",
    "\n",
    "\n",
    "#####  NOTE:\n",
    " you can convert midi to note_sequence, two ways:\n",
    " 1. USE magenta.music.midi_to_note_sequence, BUT THIS will GIVE YOU A PICKLING ERROR\n",
    " 2. install note_seq (pip install note_seq) then use note_seq.midi_to_note_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Start With the 2bar-midionly dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_unprocessed,dataset_train_info = tfds.load(\n",
    "    name=\"groove/2bar-midionly\",\n",
    "    split=tfds.Split.TRAIN,\n",
    "    try_gcs=True,\n",
    "    with_info=True)\n",
    "\n",
    "dataset_test_unprocessed = tfds.load(\n",
    "    name=\"groove/2bar-midionly\",\n",
    "    split=tfds.Split.TEST,\n",
    "    try_gcs=True)\n",
    "\n",
    "dataset_validation_unprocessed = tfds.load(\n",
    "    name=\"groove/2bar-midionly\",\n",
    "    split=tfds.Split.VALIDATION,\n",
    "    try_gcs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: TF DATASETS ARE PYTHON ITERABLES\n",
    "you can convert the dataset into a list or numpy array:\n",
    "\n",
    "   * List(dataset)\n",
    "   * tfds.as_numpy(dataset)\n",
    "    \n",
    "Lets see how many samples we've got in the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of Examples in Train Set: 18163, Test Set: 2204, Validation Set: 2252\n"
     ]
    }
   ],
   "source": [
    " # In all three sets, separate entries into individual examples \n",
    "dataset_train = dataset_train_unprocessed.batch(1)\n",
    "dataset_test  = dataset_test_unprocessed.batch(1)\n",
    "dataset_validation = dataset_validation_unprocessed.batch(1)\n",
    "\n",
    "print(\"\\n Number of Examples in Train Set: {}, Test Set: {}, Validation Set: {}\".format(\n",
    "    len(list(dataset_train)), \n",
    "    len(list(dataset_test)), \n",
    "    len(list(dataset_validation)))\n",
    "     ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: ../resources: File exists\n",
      "mkdir: ../resources/source_dataset: File exists\n",
      "--2021-04-16 10:50:49--  https://storage.googleapis.com/magentadata/datasets/groove/groove-v1.0.0-midionly.zip\n",
      "Resolving storage.googleapis.com... 2a00:1450:4003:803::2010, 142.250.185.16\n",
      "Connecting to storage.googleapis.com|2a00:1450:4003:803::2010|:443... connected.\n",
      "HTTP request sent, awaiting response... 304 Not Modified\n",
      "File '../resources/source_dataset/groove-v1.0.0-midionly.zip' not modified on server. Omitting download.\n",
      "\n",
      "Archive:  ../resources/source_dataset/groove-v1.0.0-midionly.zip\n"
     ]
    }
   ],
   "source": [
    "# Download groovemidi set (midi files and metadata of performances, not chopped files!) \n",
    "!mkdir ../resources\n",
    "!mkdir ../resources/source_dataset\n",
    "!wget -N -P ../resources/source_dataset https://storage.googleapis.com/magentadata/datasets/groove/groove-v1.0.0-midionly.zip\n",
    "!unzip -n ../resources/source_dataset/groove-v1.0.0-midionly.zip -d ../resources/source_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will start pre-process the downloaded 2-bar groove midi datasets.\n",
    "The metadata for the dataset is not available via the tfds.load() method. As a result, I have manually downloaded the groove-v1.0.0-midionly.zip dataset from here:\n",
    "        \n",
    "        https://magenta.tensorflow.org/datasets/groove\n",
    "        \n",
    "In this folder (currently in resources/source_dataset), there is a csv file containing the metadata for each of the examples. I will match each of the 2-bar examples (downloaded from tfds.load()) with the csv file available in the manually downloaded groove-v1.0.0-midionly.zip\n",
    "\n",
    "\n",
    "To keep track of the metadata, a panda's dataframe with the following fields is used\n",
    "\n",
    "* Keys from Groove MIDI Dataset:\n",
    "    * bpm\n",
    "    * drummer\n",
    "    * id \n",
    "    * midi\n",
    "    * style\n",
    "    * time_signature\n",
    "    * type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drummer</th>\n",
       "      <th>session</th>\n",
       "      <th>id</th>\n",
       "      <th>style</th>\n",
       "      <th>bpm</th>\n",
       "      <th>beat_type</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>midi_filename</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>duration</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/1</td>\n",
       "      <td>funk/groove1</td>\n",
       "      <td>138</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
       "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
       "      <td>27.872308</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/10</td>\n",
       "      <td>soul/groove10</td>\n",
       "      <td>102</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
       "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
       "      <td>37.691158</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/2</td>\n",
       "      <td>funk/groove2</td>\n",
       "      <td>105</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
       "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
       "      <td>36.351218</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/3</td>\n",
       "      <td>soul/groove3</td>\n",
       "      <td>86</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
       "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
       "      <td>44.716543</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/4</td>\n",
       "      <td>soul/groove4</td>\n",
       "      <td>80</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
       "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
       "      <td>47.987500</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    drummer                session                        id          style  \\\n",
       "0  drummer1  drummer1/eval_session   drummer1/eval_session/1   funk/groove1   \n",
       "1  drummer1  drummer1/eval_session  drummer1/eval_session/10  soul/groove10   \n",
       "2  drummer1  drummer1/eval_session   drummer1/eval_session/2   funk/groove2   \n",
       "3  drummer1  drummer1/eval_session   drummer1/eval_session/3   soul/groove3   \n",
       "4  drummer1  drummer1/eval_session   drummer1/eval_session/4   soul/groove4   \n",
       "\n",
       "   bpm beat_type time_signature  \\\n",
       "0  138      beat            4-4   \n",
       "1  102      beat            4-4   \n",
       "2  105      beat            4-4   \n",
       "3   86      beat            4-4   \n",
       "4   80      beat            4-4   \n",
       "\n",
       "                                       midi_filename  \\\n",
       "0  drummer1/eval_session/1_funk-groove1_138_beat_...   \n",
       "1  drummer1/eval_session/10_soul-groove10_102_bea...   \n",
       "2  drummer1/eval_session/2_funk-groove2_105_beat_...   \n",
       "3  drummer1/eval_session/3_soul-groove3_86_beat_4...   \n",
       "4  drummer1/eval_session/4_soul-groove4_80_beat_4...   \n",
       "\n",
       "                                      audio_filename   duration split  \n",
       "0  drummer1/eval_session/1_funk-groove1_138_beat_...  27.872308  test  \n",
       "1  drummer1/eval_session/10_soul-groove10_102_bea...  37.691158  test  \n",
       "2  drummer1/eval_session/2_funk-groove2_105_beat_...  36.351218  test  \n",
       "3  drummer1/eval_session/3_soul-groove3_86_beat_4...  44.716543  test  \n",
       "4  drummer1/eval_session/4_soul-groove4_80_beat_4...  47.987500  test  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('../resources/source_dataset/groove/info.csv', delimiter = ',')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['drummer1/eval_session'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick guide to using the panda dataframe\n",
    "(dataframe[dataframe.id == \"drummer1/eval_session/1\"][\"session\"]).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference between tfds.load(name=\"groove/2bar-midionly\") and groove-v1.0.0-midionly.zip\n",
    "\n",
    "In groove-v1.0.0-midionly.zip, we have access to full performances, while using tfds.load(name=\"groove/2bar-midionly\"), we can readily access the performance chopped into 2 bar segments. \n",
    "\n",
    "However, in the pre-chopped set, the meta data is missing. \n",
    "\n",
    "Hence, we need to find the relevant metadata in the info.csv file available groove-v1.0.0-midionly.zip. \n",
    "\n",
    "To do so, we match the beginning of the id in the chopped segments with the id in info.csv\n",
    "\n",
    "\n",
    "# Preprocessing Steps\n",
    "\n",
    "\n",
    "To preprocess the set, we will go through each of the examples in train/test/eval sets and do the following:\n",
    "\n",
    "    1. get the midi file from the \"midi\" field available from tfds.load()\n",
    "    2. convert midi to note_sequence \n",
    "    2. convert the note_sequence to HVO_Sequence\n",
    "    3. get the id from the \"id\" field available from tfds.load()\n",
    "    4. Match the beginning of the \"id\" field with the ids in the pandas dataframe (loaded from groove-v1.0.0-midionly.zip)\n",
    "    5. Store all processed/retrieved fields in a dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_append(dictionary, key, vals):\n",
    "    # Appends a value or a list of values to a key in a dictionary\n",
    "    \n",
    "    # if the values for a key are not a list, they are converted to a list and then extended with vals\n",
    "    dictionary[key]=list(dictionary[key]) if not isinstance(dictionary[key], list) else dictionary[key]\n",
    "    \n",
    "    # if vals is a single value (not a list), it's converted to a list so as to be iterable\n",
    "    vals = [vals] if not isinstance(vals, list) else vals\n",
    "        \n",
    "    # append new values \n",
    "    for val in vals:\n",
    "        dictionary[key].append(val)\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "def convert_groove_midi_dataset(dataset, beat_division_factors=[4], csv_dataframe_info=None):\n",
    "    \n",
    "    dataset_dict_processed = dict()\n",
    "    dataset_dict_processed.update({\n",
    "        \"drummer\":[],\n",
    "        \"session\":[],\n",
    "        \"loop_id\":[],  # the id of the recording from which the loop is extracted\n",
    "        \"master_id\":[], # the id of the recording from which the loop is extracted\n",
    "        \"style_primary\":[],\n",
    "        \"style_secondary\":[],\n",
    "        \"bpm\":[],\n",
    "        \"beat_type\":[],\n",
    "        \"time_signature\":[],\n",
    "        \"full_midi_filename\":[],\n",
    "        \"full_audio_filename\":[],\n",
    "        \"midi\":[],\n",
    "        \"note_sequence\":[],\n",
    "        \"hvo_sequence\":[],\n",
    "    })\n",
    "    \n",
    "    for features in dataset:\n",
    "        \n",
    "        # Features to be extracted from the dataset\n",
    "        \n",
    "        note_sequence = note_seq.midi_to_note_sequence(tfds.as_numpy(features[\"midi\"][0]))\n",
    "        \n",
    "        \n",
    "        if note_sequence.notes: # ignore if no notes in note_sequence (i.e. empty 2 bar sequence)\n",
    "                        \n",
    "            _hvo_seq = note_sequence_to_hvo_sequence(\n",
    "                ns = note_sequence, \n",
    "                drum_mapping = ROLAND_REDUCED_MAPPING,\n",
    "                beat_division_factors = beat_division_factors\n",
    "            )\n",
    "            \n",
    "            if not csv_dataframe_info.empty:\n",
    "\n",
    "                # Master ID for the Loop\n",
    "                main_id = features[\"id\"].numpy()[0].decode(\"utf-8\").split(\":\")[0]\n",
    "\n",
    "                # Get the relevant series from the dataframe\n",
    "                df = csv_dataframe_info[csv_dataframe_info.id == main_id]\n",
    "                \n",
    "                # Update the dictionary associated with the metadata\n",
    "                dict_append(dataset_dict_processed, \"drummer\", df[\"drummer\"].to_numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"session\", df[\"session\"].to_numpy()[0].split(\"/\")[-1])\n",
    "                dict_append(dataset_dict_processed, \"loop_id\", features[\"id\"].numpy()[0].decode(\"utf-8\"))\n",
    "                dict_append(dataset_dict_processed, \"master_id\", main_id)\n",
    "\n",
    "                style_full = df[\"style\"].to_numpy()[0]\n",
    "                style_primary = style_full.split(\"/\")[0]\n",
    "                dict_append(dataset_dict_processed, \"style_primary\", style_primary)\n",
    "\n",
    "                if \"/\" in style_full:\n",
    "                    style_secondary = style_full.split(\"/\")[1]\n",
    "                    dict_append(dataset_dict_processed, \"style_secondary\", style_secondary)\n",
    "                else:\n",
    "                    dict_append(dataset_dict_processed, \"style_secondary\", [\"None\"])\n",
    "\n",
    "                dict_append(dataset_dict_processed, \"bpm\", df[\"bpm\"].to_numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"beat_type\", df[\"beat_type\"].to_numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"time_signature\", df[\"time_signature\"].to_numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"full_midi_filename\", df[\"midi_filename\"].to_numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"full_audio_filename\", df[\"audio_filename\"].to_numpy()[0])\n",
    "\n",
    "                dict_append(dataset_dict_processed, \"midi\", features[\"midi\"].numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"note_sequence\", [note_sequence])\n",
    "                        \n",
    "            dict_append(dataset_dict_processed, \"hvo_sequence\", _hvo_seq)\n",
    "\n",
    "        else:\n",
    "            pass \n",
    "            \n",
    "    return dataset_dict_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 4.07 s, total: 1min 44s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Process Training Set\n",
    "dataset_train = dataset_train_unprocessed.batch(1)\n",
    "dataset_train_processed = convert_groove_midi_dataset(\n",
    "    dataset = dataset_train, \n",
    "    beat_division_factors=[4], \n",
    "    csv_dataframe_info=dataframe\n",
    ")\n",
    "\n",
    "# Process Test Set\n",
    "dataset_test = dataset_test_unprocessed.batch(1)\n",
    "dataset_test_processed = convert_groove_midi_dataset(\n",
    "    dataset = dataset_test, \n",
    "    beat_division_factors=[4], \n",
    "    csv_dataframe_info=dataframe)\n",
    "\n",
    "# Process Validation Set\n",
    "dataset_validation = dataset_validation_unprocessed.batch(1)\n",
    "dataset_validation_processed = convert_groove_midi_dataset(\n",
    "    dataset = dataset_validation, \n",
    "    beat_division_factors=[4], \n",
    "    csv_dataframe_info=dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order the pre-processed set\n",
    "The batching process shuffles the dataset. However, we prefer to store the dataset in sequential order. Hence, we need to manually order the dataset. In this tutorial, I order the sequences by loop_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dictionary_by_key (dictionary_to_sort, key_used_to_sort):\n",
    "    # sorts a dictionary according to the list within a given key\n",
    "    sorted_ids=np.argsort(dictionary_to_sort[key_used_to_sort])\n",
    "    for key in dictionary_to_sort.keys():\n",
    "        dictionary_to_sort[key]=[dictionary_to_sort[key][i] for i in sorted_ids]\n",
    "    return dictionary_to_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the sets using ids\n",
    "dataset_train_processed = sort_dictionary_by_key(dataset_train_processed, \"loop_id\")\n",
    "dataset_test_processed = sort_dictionary_by_key(dataset_test_processed, \"loop_id\")\n",
    "dataset_validation_processed = sort_dictionary_by_key(dataset_validation_processed, \"loop_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "--------------------------------------\n",
    "\n",
    "# Storing Pre-Processed Sets\n",
    "\n",
    "The folder structure is as follows:\n",
    "\n",
    "../processed_dataset\n",
    "\n",
    "      |\n",
    "      |--> /Processed_On_%d_%m_%Y_at_%H_%M_hrs\n",
    "            |\n",
    "            |--> /GrooveMIDI_processed_{train, test, or validation}\n",
    "                    |\n",
    "                    |--> hvo_sequence.obj\n",
    "                    |\n",
    "                    |--> note_sequence.obj\n",
    "                    |\n",
    "                    |--> midi.obj\n",
    "                    |\n",
    "                    |--> midi.obj\n",
    "                    |\n",
    "                    |--> metadata.csv\n",
    "                    \n",
    "                    \n",
    "The midi files, hvo_sequences and note_sequences along with corresponding metadata are all saved in separate files. The order of entries in all these files match one another (increasing in alpha-numeric order of \"loopid\"s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMP INTO A PICKLE FILE\n",
    "def store_dataset_as_pickle(dataset_list, \n",
    "                            filename_list, \n",
    "                            root_dir = \"../processed_dataset\",\n",
    "                            append_datetime=True, \n",
    "                            features_with_separate_picklefile = [\"hvo\", \"midi\", \"note_seq\"]\n",
    "                           ):\n",
    "\n",
    "    #filename = filename.split(\".obj\")[0]\n",
    "    path = root_dir\n",
    "    \n",
    "    if append_datetime:\n",
    "        now = datetime.now()\n",
    "        dt_string = now.strftime(\"%d_%m_%Y_at_%H_%M_hrs\")\n",
    "    else:\n",
    "        dt_string =\"\"\n",
    "        \n",
    "    path = os.path.join(path, \"Processed_On_\"+dt_string)\n",
    "    \n",
    "    if not os.path.exists (path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    currentNotebook = ipyparams.notebook_name\n",
    "    print(\"Copying Source Code from %s to %s\" % (os.path.join(os.getcwd(), currentNotebook), path))\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    # copy2(os.path.join(os.getcwd(), currentNotebook), path) \n",
    "    \n",
    "    for i, dataset in enumerate(dataset_list):\n",
    "\n",
    "        subdirectory = os.path.join(path, filename_list[i])\n",
    "        if not os.path.exists (subdirectory):\n",
    "            os.makedirs(subdirectory)\n",
    "            \n",
    "        print(\"-\"*100)\n",
    "        print(\"-\"*100)\n",
    "        print(\"Processing %s folder\" % subdirectory)\n",
    "        print(\"-\"*100)\n",
    "        print(\"-\"*100)\n",
    "        \n",
    "        # Create Metadata File\n",
    "        csv_dataframe = pd.DataFrame()\n",
    "        \n",
    "        for k in dataset.keys():\n",
    "            if k not in features_with_separate_picklefile:\n",
    "                csv_dataframe[k] = dataset[k]\n",
    "        \n",
    "        csv_dataframe.to_csv(os.path.join(subdirectory, \"metadata.csv\"))\n",
    "        \n",
    "        print(\"Metadata created!\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        for feature in features_with_separate_picklefile:\n",
    "            if feature in dataset.keys():\n",
    "                dataset_filehandler = open(os.path.join(subdirectory, \"%s_data.obj\"%feature),\"wb\")\n",
    "                print(feature)\n",
    "                print(dataset_filehandler)\n",
    "                pickle.dump(dataset[feature],  dataset_filehandler)\n",
    "                dataset_filehandler.close()\n",
    "                print(\"feature %s pickled at %s\" % (feature, os.path.join(subdirectory, \"%s.obj\"%filename_list[i].split(\".\")[0])))\n",
    "                print(\"-\"*100)\n",
    "\n",
    "            else:\n",
    "                 raise Warning(\"Feature is not available: \", feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying Source Code from /Users/behzadhaki/Documents/School Work (Stored on Catalina and Mega Only)/GrooveMIDI2HVO_PreProcessing/pre_processing_tutorial/ to ../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing ../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_train folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Metadata created!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "hvo_sequence\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_train/hvo_sequence_data.obj'>\n",
      "feature hvo_sequence pickled at ../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_train/GrooveMIDI_processed_train.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "midi\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_train/midi_data.obj'>\n",
      "feature midi pickled at ../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_train/GrooveMIDI_processed_train.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "note_sequence\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_train/note_sequence_data.obj'>\n",
      "feature note_sequence pickled at ../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_train/GrooveMIDI_processed_train.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing ../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_test folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Metadata created!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "hvo_sequence\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_test/hvo_sequence_data.obj'>\n",
      "feature hvo_sequence pickled at ../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_test/GrooveMIDI_processed_test.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "midi\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_test/midi_data.obj'>\n",
      "feature midi pickled at ../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_test/GrooveMIDI_processed_test.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "note_sequence\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_test/note_sequence_data.obj'>\n",
      "feature note_sequence pickled at ../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_test/GrooveMIDI_processed_test.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing ../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_validation folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Metadata created!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "hvo_sequence\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_validation/hvo_sequence_data.obj'>\n",
      "feature hvo_sequence pickled at ../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_validation/GrooveMIDI_processed_validation.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "midi\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_validation/midi_data.obj'>\n",
      "feature midi pickled at ../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_validation/GrooveMIDI_processed_validation.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "note_sequence\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_validation/note_sequence_data.obj'>\n",
      "feature note_sequence pickled at ../processed_dataset/Processed_On_16_04_2021_at_10_48_hrs/GrooveMIDI_processed_validation/GrooveMIDI_processed_validation.obj\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_list = [dataset_train_processed,\n",
    "               dataset_test_processed,\n",
    "               dataset_validation_processed]\n",
    "\n",
    "filename_list = [\"GrooveMIDI_processed_train\",\n",
    "                \"GrooveMIDI_processed_test\",\n",
    "                \"GrooveMIDI_processed_validation\"]\n",
    "\n",
    "store_dataset_as_pickle(dataset_list, \n",
    "                        filename_list,\n",
    "                        root_dir=\"../processed_dataset\",\n",
    "                        append_datetime=True,\n",
    "                        features_with_separate_picklefile = [\"hvo_sequence\", \"midi\", \"note_sequence\"]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "----------\n",
    "\n",
    "### Using Pre-Processed Sets After Storing\n",
    "\n",
    "Now, we can import the pre-processed sets easily into our scripts without going through this procedure. \n",
    "\n",
    "To do so, load the pickle files and the metadata from corresponding subfolders!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../processed_dataset/Processed_On_16_04_2021_at_10_15_hrs/GrooveMIDI_processed_train/hvo_data.obj\n",
      "Dataset Size: 17108 \n",
      " Features:  ['Unnamed: 0', 'drummer', 'session', 'loop_id', 'master_id', 'style_primary', 'style_secondary', 'bpm', 'beat_type', 'time_signature', 'full_midi_filename', 'full_audio_filename']\n"
     ]
    }
   ],
   "source": [
    "source_path = \"../processed_dataset/Processed_On_16_04_2021_at_10_15_hrs\"\n",
    "print(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"hvo_data.obj\"))\n",
    "train_file = open(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"hvo_sequence_data.obj\"),'rb')\n",
    "train_set = pickle.load(train_file)\n",
    "metadata = pd.read_csv(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"metadata.csv\"))\n",
    "\n",
    "features_in_metadata = list(metadata.columns)\n",
    "\n",
    "dataset_size = len(train_set)\n",
    "\n",
    "print(\"Dataset Size: %d \\n Features: \" % dataset_size, features_in_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at a random entry!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Number: 9448, Primary Style: dominican-merengue, Secondary Style: latin\n"
     ]
    }
   ],
   "source": [
    "ix =  int(np.random.random_sample()*dataset_size)\n",
    "print(\"Sample Number: %d, Primary Style: %s, Secondary Style: %s\" % (ix, \n",
    "                                                                     metadata[\"style_secondary\"][ix], \n",
    "                                                                     metadata[\"style_primary\"][ix])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Models must be owned by only a single document, Toolbar(id='1025', ...) is already in a doc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3616ba94e689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../pre_processing_tutorial/misc/temp.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/bokeh/io/showing.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(obj, browser, new, notebook_handle, notebook_url, **kw)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_notebook_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'app'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show_with_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook_handle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;31m#-----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/bokeh/io/showing.py\u001b[0m in \u001b[0;36m_show_with_state\u001b[0;34m(obj, state, browser, new, notebook_handle)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mcomms_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_notebook_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'doc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mshown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/bokeh/io/notebook.py\u001b[0m in \u001b[0;36mrun_notebook_hook\u001b[0;34m(notebook_type, action, *args, **kw)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_HOOKS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnotebook_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"notebook hook for %r did not install %r action\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnotebook_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_HOOKS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnotebook_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;31m#-----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/bokeh/io/notebook.py\u001b[0m in \u001b[0;36mshow_doc\u001b[0;34m(obj, state, notebook_handle)\u001b[0m\n\u001b[1;32m    502\u001b[0m     '''\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotebook_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/bokeh/document/document.py\u001b[0m in \u001b[0;36madd_root\u001b[0;34m(self, model, setter)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_roots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pop_all_models_freeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trigger_on_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRootAddedEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/bokeh/document/document.py\u001b[0m in \u001b[0;36m_pop_all_models_freeze\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_models_freeze_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_models_freeze_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recompute_all_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recompute_all_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/bokeh/document/document.py\u001b[0m in \u001b[0;36m_recompute_all_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detach_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_attach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecomputed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_models_by_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecomputed_by_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/bokeh/model.py\u001b[0m in \u001b[0;36m_attach_document\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    672\u001b[0m         '''\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_document\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_document\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Models must be owned by only a single document, %r is already in a doc\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Models must be owned by only a single document, Toolbar(id='1025', ...) is already in a doc"
     ]
    }
   ],
   "source": [
    "fig = train_set[ix].to_html_plot(filename=\"../pre_processing_tutorial/misc/temp.html\")\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , ..., -0.00057372,\n",
       "       -0.00057372,  0.        ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[ix].save_audio(filename=\"../pre_processing_tutorial/misc/temp.wav\", sf_path=\"../hvo_sequence/soundfonts/Standard_Drum_Kit.sf2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magent_1_7_tf",
   "language": "python",
   "name": "magent_1_7_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
